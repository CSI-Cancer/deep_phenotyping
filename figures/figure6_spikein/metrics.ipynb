{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f6a2e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall precision: 0.8861\n",
      "Overall recall   : 0.9821\n",
      "Overall F1       : 0.9317\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1.  Load per‑slide metrics\n",
    "# ---------------------------------------------------------------------\n",
    "df = pd.read_csv(\"/mnt/deepstore/Final_DeepPhenotyping/figures/figure6_spikein/sk_br_3_metrics.csv\")      # columns: slide, precision, recall, f1, support\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2.  Reconstruct confusion‑matrix pieces for each slide\n",
    "#     Assumptions:\n",
    "#       • support = TP + FN  (ground‑truth positives on that slide)\n",
    "#       • precision = TP / (TP + FP)\n",
    "#       • recall    = TP / (TP + FN)  (= TP / support)\n",
    "# ---------------------------------------------------------------------\n",
    "df[\"TP\"] = df[\"recall\"]   * df[\"support\"]\n",
    "df[\"FP\"] = df[\"TP\"] * (1 / df[\"precision\"] - 1)\n",
    "df[\"FN\"] = df[\"support\"]  - df[\"TP\"]\n",
    "\n",
    "# sanity check – any division‑by‑zero or NaN means bogus inputs\n",
    "if df[[\"TP\",\"FP\",\"FN\"]].isna().any().any():\n",
    "    raise ValueError(\"Encountered NaN – check precision/recall values (cannot be 0).\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3.  Aggregate and compute global (micro‑average) metrics\n",
    "# ---------------------------------------------------------------------\n",
    "TP_tot = df[\"TP\"].sum()\n",
    "FP_tot = df[\"FP\"].sum()\n",
    "FN_tot = df[\"FN\"].sum()\n",
    "\n",
    "precision_overall = TP_tot / (TP_tot + FP_tot)\n",
    "recall_overall    = TP_tot / (TP_tot + FN_tot)\n",
    "f1_overall        = 2 * precision_overall * recall_overall / (precision_overall + recall_overall)\n",
    "\n",
    "print(f\"Overall precision: {precision_overall:.4f}\")\n",
    "print(f\"Overall recall   : {recall_overall:.4f}\")\n",
    "print(f\"Overall F1       : {f1_overall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd80750d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall precision: 0.9707\n",
      "Overall recall   : 0.9028\n",
      "Overall F1       : 0.9355\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1.  Load per‑slide metrics\n",
    "# ---------------------------------------------------------------------\n",
    "df = pd.read_csv(\"/mnt/deepstore/Final_DeepPhenotyping/figures/figure6_spikein/hpaec_metrics.csv\")      # columns: slide, precision, recall, f1, support\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2.  Reconstruct confusion‑matrix pieces for each slide\n",
    "#     Assumptions:\n",
    "#       • support = TP + FN  (ground‑truth positives on that slide)\n",
    "#       • precision = TP / (TP + FP)\n",
    "#       • recall    = TP / (TP + FN)  (= TP / support)\n",
    "# ---------------------------------------------------------------------\n",
    "df[\"TP\"] = df[\"recall\"]   * df[\"support\"]\n",
    "df[\"FP\"] = df[\"TP\"] * (1 / df[\"precision\"] - 1)\n",
    "df[\"FN\"] = df[\"support\"]  - df[\"TP\"]\n",
    "\n",
    "# sanity check – any division‑by‑zero or NaN means bogus inputs\n",
    "if df[[\"TP\",\"FP\",\"FN\"]].isna().any().any():\n",
    "    raise ValueError(\"Encountered NaN – check precision/recall values (cannot be 0).\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3.  Aggregate and compute global (micro‑average) metrics\n",
    "# ---------------------------------------------------------------------\n",
    "TP_tot = df[\"TP\"].sum()\n",
    "FP_tot = df[\"FP\"].sum()\n",
    "FN_tot = df[\"FN\"].sum()\n",
    "\n",
    "precision_overall = TP_tot / (TP_tot + FP_tot)\n",
    "recall_overall    = TP_tot / (TP_tot + FN_tot)\n",
    "f1_overall        = 2 * precision_overall * recall_overall / (precision_overall + recall_overall)\n",
    "\n",
    "print(f\"Overall precision: {precision_overall:.4f}\")\n",
    "print(f\"Overall recall   : {recall_overall:.4f}\")\n",
    "print(f\"Overall F1       : {f1_overall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3a0d588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall precision: 0.9117\n",
      "Overall recall   : 0.9473\n",
      "Overall F1       : 0.9292\n",
      "Mean F1 score    : 0.8811\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1.  Load per‑slide metrics\n",
    "# ---------------------------------------------------------------------\n",
    "df = pd.read_csv(\"/mnt/deepstore/Final_DeepPhenotyping/figures/figure7_patient/imCTC_metrics.csv\")      # columns: slide, precision, recall, f1, support\n",
    "\n",
    "#lowercase column names\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "#remove any rows where precision is 0\n",
    "df = df[df[\"precision\"] != 0]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2.  Reconstruct confusion‑matrix pieces for each slide\n",
    "#     Assumptions:\n",
    "#       • support = TP + FN  (ground‑truth positives on that slide)\n",
    "#       • precision = TP / (TP + FP)\n",
    "#       • recall    = TP / (TP + FN)  (= TP / support)\n",
    "# ---------------------------------------------------------------------\n",
    "df[\"TP\"] = df[\"recall\"]   * df[\"support\"]\n",
    "df[\"FP\"] = df[\"TP\"] * (1 / df[\"precision\"] - 1)\n",
    "df[\"FN\"] = df[\"support\"]  - df[\"TP\"]\n",
    "\n",
    "# sanity check – any division‑by‑zero or NaN means bogus inputs\n",
    "if df[[\"TP\",\"FP\",\"FN\"]].isna().any().any():\n",
    "    raise ValueError(\"Encountered NaN – check precision/recall values (cannot be 0).\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3.  Aggregate and compute global (micro‑average) metrics\n",
    "# ---------------------------------------------------------------------\n",
    "TP_tot = df[\"TP\"].sum()\n",
    "FP_tot = df[\"FP\"].sum()\n",
    "FN_tot = df[\"FN\"].sum()\n",
    "\n",
    "precision_overall = TP_tot / (TP_tot + FP_tot)\n",
    "recall_overall    = TP_tot / (TP_tot + FN_tot)\n",
    "f1_overall        = 2 * precision_overall * recall_overall / (precision_overall + recall_overall)\n",
    "\n",
    "print(f\"Overall precision: {precision_overall:.4f}\")\n",
    "print(f\"Overall recall   : {recall_overall:.4f}\")\n",
    "print(f\"Overall F1       : {f1_overall:.4f}\")\n",
    "\n",
    "#print mean F1 score\n",
    "mean_f1 = df[\"f1\"].mean()\n",
    "print(f\"Mean F1 score    : {mean_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "766c18ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall precision: 0.9651\n",
      "Overall recall   : 0.8011\n",
      "Overall F1       : 0.8754\n",
      "Mean F1 score    : 0.8352\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1.  Load per‑slide metrics\n",
    "# ---------------------------------------------------------------------\n",
    "df = pd.read_csv(\"/mnt/deepstore/Final_DeepPhenotyping/figures/figure7_patient/epiCTC_metrics.csv\")      # columns: slide, precision, recall, f1, support\n",
    "\n",
    "#lowercase column names\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "#remove any rows where precision is 0\n",
    "df = df[df[\"precision\"] != 0]\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2.  Reconstruct confusion‑matrix pieces for each slide\n",
    "#     Assumptions:\n",
    "#       • support = TP + FN  (ground‑truth positives on that slide)\n",
    "#       • precision = TP / (TP + FP)\n",
    "#       • recall    = TP / (TP + FN)  (= TP / support)\n",
    "# ---------------------------------------------------------------------\n",
    "df[\"TP\"] = df[\"recall\"]   * df[\"support\"]\n",
    "df[\"FP\"] = df[\"TP\"] * (1 / df[\"precision\"] - 1)\n",
    "df[\"FN\"] = df[\"support\"]  - df[\"TP\"]\n",
    "\n",
    "# sanity check – any division‑by‑zero or NaN means bogus inputs\n",
    "if df[[\"TP\",\"FP\",\"FN\"]].isna().any().any():\n",
    "    raise ValueError(\"Encountered NaN – check precision/recall values (cannot be 0).\")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3.  Aggregate and compute global (micro‑average) metrics\n",
    "# ---------------------------------------------------------------------\n",
    "TP_tot = df[\"TP\"].sum()\n",
    "FP_tot = df[\"FP\"].sum()\n",
    "FN_tot = df[\"FN\"].sum()\n",
    "\n",
    "precision_overall = TP_tot / (TP_tot + FP_tot)\n",
    "recall_overall    = TP_tot / (TP_tot + FN_tot)\n",
    "f1_overall        = 2 * precision_overall * recall_overall / (precision_overall + recall_overall)\n",
    "\n",
    "print(f\"Overall precision: {precision_overall:.4f}\")\n",
    "print(f\"Overall recall   : {recall_overall:.4f}\")\n",
    "print(f\"Overall F1       : {f1_overall:.4f}\")\n",
    "\n",
    "#print mean F1 score\n",
    "mean_f1 = df[\"f1\"].mean()\n",
    "print(f\"Mean F1 score    : {mean_f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prism",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
